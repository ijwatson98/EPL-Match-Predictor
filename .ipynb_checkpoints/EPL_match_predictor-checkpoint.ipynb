{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "matches = pd.read_csv(\"matches.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.drop([\"round\", \n",
    "              \"comp\", \n",
    "              \"season\", \n",
    "              \"attendance\", \n",
    "              \"notes\", \n",
    "              \"captain\", \n",
    "              \"formation\", \n",
    "              \"referee\", \n",
    "              \"match report\", \n",
    "              \"notes\"], \n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categoric variables to numeric for machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"date\"] = pd.to_datetime(matches[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"venue_code\"] = matches[\"venue\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches[\"day_code\"] = matches[\"date\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve just hour from ko time - time of day may affect performance\n",
    "matches[\"hour\"] = matches[\"time\"].str.replace(\":.+\", \"\", regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict to rename teams so they match in home/away column\n",
    "class MissingDict(dict):\n",
    "    __missing__ = lambda self, key: key\n",
    "    \n",
    "map_values = {  \n",
    "    \"Brighton and Hove Albion\": \"Brighton\",\n",
    "    \"Manchester United\": \"Manchester Utd\",\n",
    "    \"Newcastle United\": \"Newcastle Utd\",\n",
    "    \"Sheffield United\": \"Sheffield Utd\",\n",
    "    \"Tottenham Hotspur\": \"Tottenham\",\n",
    "    \"West Bromwich Albion\": \"West Brom\",\n",
    "    \"West Ham United\": \"West Ham\",\n",
    "    \"Wolverhampton Wanderers\": \"Wolves\",    \n",
    "}\n",
    "mapping = MissingDict(**map_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['team'] = matches['team'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine points acquired\n",
    "matches[\"points\"] = matches[\"result\"].apply(lambda row: 3 if row==\"W\" else 1 if row==\"D\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert W/L/D to numbers for classification\n",
    "matches[\"results_class\"] = matches[\"result\"].apply(lambda row: 2 if row==\"W\" else 1 if row==\"D\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches.sort_values('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rolling averages based on previous 4 games\n",
    "cols = ['points', 'gf', 'ga', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt', 'poss', 'xg', 'xga']\n",
    "new_cols = [f\"{c}_rolling\" for c in cols]\n",
    "matches[new_cols] = matches.groupby('team')[cols].transform(lambda x: x.rolling(4).mean().shift().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by team\n",
    "grp_matches = matches.groupby(\"team\").apply(lambda a: a[:]).drop('team', axis=1).droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_matches.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep important columns that have potential impact on performance\n",
    "avg_matches = grp_matches[['date', \n",
    "                           'team',\n",
    "                           'opponent',\n",
    "                           'venue_code', \n",
    "                           'hour', \n",
    "                           'day_code', \n",
    "                           'points_rolling', \n",
    "                           'gf_rolling', \n",
    "                           'ga_rolling', \n",
    "                           'sh_rolling', \n",
    "                           'sot_rolling', \n",
    "                           'dist_rolling', \n",
    "                           'fk_rolling', \n",
    "                           'pk_rolling', \n",
    "                           'pkatt_rolling',\n",
    "                           'poss_rolling',\n",
    "                           'xg_rolling', \n",
    "                           'xga_rolling', \n",
    "                           'results_class']].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in to home and awya matches based on venue code\n",
    "home_matches = avg_matches[avg_matches[\"venue_code\"]==1].sort_values(\"date\")\n",
    "away_matches = avg_matches[avg_matches[\"venue_code\"]==0].sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remerge so no matches are repeated\n",
    "merge_matches = pd.merge(home_matches, away_matches, \n",
    "                         left_on=[\"date\", \"team\", \"opponent\"], \n",
    "                         right_on=[\"date\", \"opponent\", \"team\"], \n",
    "                         suffixes=('_home', '_away')).sort_values(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_matches.drop([\"opponent_home\", \"opponent_away\", \"venue_code_home\", \"venue_code_away\", \"results_class_away\", \"hour_away\", \"day_code_away\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_matches.rename({\"hour_home\": \"hour\", \"day_code_home\": \"day_code\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_matches[\"team_home_code\"] = merge_matches[\"team_home\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_matches[\"team_away_code\"] = merge_matches[\"team_away\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns with average stat differences between the two teams\n",
    "merge_matches['points_rolling_diff'] = (merge_matches['points_rolling_home']-merge_matches['points_rolling_away'])\n",
    "merge_matches['gf_rolling_diff'] = (merge_matches['gf_rolling_home']-merge_matches['gf_rolling_away'])\n",
    "merge_matches['ga_rolling_diff'] = (merge_matches['ga_rolling_home']-merge_matches['ga_rolling_away'])\n",
    "merge_matches['sh_rolling_diff'] = (merge_matches['sh_rolling_home']-merge_matches['sh_rolling_away'])\n",
    "merge_matches['sot_rolling_diff'] = (merge_matches['sot_rolling_home']-merge_matches['sot_rolling_away'])\n",
    "merge_matches['poss_rolling_diff'] = (merge_matches['poss_rolling_home']-merge_matches['poss_rolling_away'])\n",
    "merge_matches['xg_rolling_diff'] = (merge_matches['xg_rolling_home']-merge_matches['xg_rolling_away'])\n",
    "merge_matches['xga_rolling_diff'] = (merge_matches['xga_rolling_home']-merge_matches['xga_rolling_away'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final column features\n",
    "final_df = merge_matches[['date',\n",
    "                          'hour', \n",
    "                          'day_code', \n",
    "                          'team_home',\n",
    "                          'team_away', \n",
    "                          'points_rolling_diff', \n",
    "                          'gf_rolling_diff', \n",
    "                          'ga_rolling_diff', \n",
    "                          'sh_rolling_diff', \n",
    "                          'sot_rolling_diff', \n",
    "                          'poss_rolling_diff', \n",
    "                          'xg_rolling_diff', \n",
    "                          'xga_rolling_diff', \n",
    "                          'results_class_home']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe correlations between features and target \n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(final_df.corr()[['results_class_home']].sort_values(\"results_class_home\", ascending=False), annot=True, cmap=\"mako\", vmax=1, vmin=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert team names to numeric codes for machine learning model\n",
    "final_df[\"team_home_code\"] = final_df[\"team_home\"].astype(\"category\").cat.codes\n",
    "final_df[\"team_away_code\"] = final_df[\"team_away\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = final_df[final_df[\"date\"] < \"2022-01-01\"].select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = final_df[final_df[\"date\"] > \"2022-01-01\"].select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only numeric features for model\n",
    "final_df = final_df.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split based on time - 67% train 33% test\n",
    "import numpy as np \n",
    "\n",
    "train, test = np.split(final_df, [int(.67*len(final_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise feature values\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# d = preprocessing.normalize(final_df.drop(\"results_class_home\", axis=1), axis=0)\n",
    "# scaled_df = pd.DataFrame(d, columns=final_df.drop(\"results_class_home\", axis=1).columns)\n",
    "# scaled_df = scaled_df.join(final_df[\"results_class_home\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "#test/train split - stratified sampling (equal weights of each class in test/train)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(final_df.drop(\"results_class_home\", axis=1), final_df[\"results_class_home\"], test_size=0.2, stratify = final_df[\"results_class_home\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"results_class_home\", axis=1)\n",
    "y_train = train[\"results_class_home\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(\"results_class_home\", axis=1)\n",
    "y_test = test[\"results_class_home\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viusalise general relationship between variables and target\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "ax.set_xlabel('Target', fontsize=10)\n",
    "ax.set_ylabel('Feature', fontsize='medium')\n",
    "\n",
    "x=y_train\n",
    "\n",
    "for i in range(len(X_train.columns)):\n",
    "    y=X_train.iloc[:,i]\n",
    "    plt.scatter(y=y, x=x, label=X_train.columns[i])\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x, p(x))\n",
    "    \n",
    "ax.legend(loc='best', ncol=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import hp, Trials, fmin, tpe, STATUS_OK\n",
    "from hyperopt.pyll import scope\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModelfromTrials(trials):\n",
    "    valid_trial_list = [trial for trial in trials\n",
    "                            if STATUS_OK == trial['result']['status']]\n",
    "    losses = [ float(trial['result']['loss']) for trial in valid_trial_list]\n",
    "    index_having_minumum_loss = np.argmin(losses)\n",
    "    best_trial_obj = valid_trial_list[index_having_minumum_loss]\n",
    "    return best_trial_obj['result']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbreg = xgb.XGBRegressor(objective=\"reg:squarederror\", \n",
    "#                           random_state=42\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = xgbreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_xgbreg(space):\n",
    "    \n",
    "#     model = xgb.XGBRegressor(objective=\"reg:squarederror\", \n",
    "#                              max_depth=int(space['max_depth']),\n",
    "#                              min_child_weight=int(space['min_child_weight']),\n",
    "#                              n_estimators=int(space['n_estimators']),\n",
    "#                              eval_metric=\"rmse\",\n",
    "#                              early_stopping_rounds=10,\n",
    "#                              random_state=42\n",
    "#                             )\n",
    "    \n",
    "#     evaluation=[(X_test, y_test)]\n",
    "    \n",
    "#     model.fit(X_train, y_train, eval_set=evaluation, verbose=False)\n",
    "    \n",
    "#     y_pred = model.predict(X_test)\n",
    "#     score = r2_score(y_test, y_pred)\n",
    "    \n",
    "#     loss = 1 - score\n",
    "    \n",
    "#     return {'loss': loss, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space={'max_depth': hp.quniform(\"max_depth\", 1, 18, 1),\n",
    "#        'min_child_weight' : hp.quniform('min_child_weight', 0, 1000, 1),\n",
    "#        'n_estimators': hp.quniform(\"n_estimators\", 1, 1000, 1)\n",
    "#       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbreg_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_xgb = fmin(\n",
    "#     fn=objective_xgbreg,\n",
    "#     space=space,\n",
    "#     algo=tpe.suggest,\n",
    "#     trials=xgb_trials,\n",
    "#     max_evals=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_params_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbreg_model = getBestModelfromTrials(xgbreg_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = xgbreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_rnd = np.around(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgbreg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf = xgb.XGBClassifier(objective=\"multi:softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pred = xgbclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgbclf(space):\n",
    "    \n",
    "    model = xgb.XGBClassifier(objective=\"multi:softmax\", \n",
    "                              num_class=3,\n",
    "                              max_depth=space['max_depth'],\n",
    "                              min_child_weight=space['min_child_weight'],\n",
    "                              n_estimators=space['n_estimators'],\n",
    "                              gamma=space['gamma'],\n",
    "                              learning_rate=space['learning_rate'],\n",
    "                              reg_lambda=space['reg_lambda'],\n",
    "                              eval_metric=\"mlogloss\",\n",
    "                              early_stopping_rounds=space['early_stopping_rounds'],\n",
    "                              subsample=space['subsample']\n",
    "                             )\n",
    "    \n",
    "    evaluation=[(X_test, y_test)]\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=evaluation, verbose=False)\n",
    "    \n",
    "    y_pred_probs = model.predict_proba(X_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    loss = 1-score\n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': scope.int(hp.quniform(\"max_depth\", 1, 10, 1)),\n",
    "       'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 100, 5)),\n",
    "       'n_estimators': scope.int(hp.quniform(\"n_estimators\", 1, 1000, 50)),\n",
    "       'gamma': hp.quniform('gamma', 0, 1, 0.05),\n",
    "       'learning_rate': hp.quniform('learning_rate', 0.01, 0.2, 0.005),\n",
    "       'reg_lambda': hp.choice('reg_lambda', [0.1, 1.0, 5.0, 10.0, 50.0, 100.0]),\n",
    "       'early_stopping_rounds': hp.quniform('early_stopping_rounds', 10, 100, 5),\n",
    "       'subsample': hp.quniform('subsample', 0.5, 1, 0.05)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgbclf = fmin(\n",
    "    fn=objective_xgbclf,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    trials=xgbclf_trials,\n",
    "    max_evals=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params_xgbclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{'early_stopping_rounds': 45.0,\n",
    " 'gamma': 0.1,\n",
    " 'learning_rate': 0.11,\n",
    " 'max_depth': 5.0,\n",
    " 'min_child_weight': 0.0,\n",
    " 'n_estimators': 150.0,\n",
    " 'reg_lambda': 1,\n",
    " 'subsample': 0.65}\n",
    " accuracy: 0.5357142857142857\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf = getBestModelfromTrials(xgbclf_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation=[(X_train, y_train), (X_test, y_test)]\n",
    "xgbclf.fit(X_train, y_train, eval_set=evaluation, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgbclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbclf.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xgbclf.evals_result()\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(results[\"validation_0\"][\"mlogloss\"], label=\"Training loss\")\n",
    "plt.plot(results[\"validation_1\"][\"mlogloss\"], label=\"Validation loss\")\n",
    "plt.axvline(xgbclf.best_ntree_limit, color=\"gray\", label=\"Optimal tree number\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = xgbclf_model.feature_importances_.argsort()\n",
    "plt.barh(X_train.columns[sort], xgbclf_model.feature_importances_[sort])\n",
    "plt.xlabel(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Classifier Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Logistic Regression\",\"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    LogisticRegression(),\n",
    "    SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    SVC(gamma=2, C=1, probability=True),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    # prediction_proba = clf.predict_proba(X_test)\n",
    "    # logloss = log_loss(y_test,prediction_proba)\n",
    "    # precision, recall, fscore, support = score(y_test, prediction)\n",
    "    # conf_martrix = confusion_matrix(y_test, prediction)\n",
    "    # clas_report = classification_report(y_test, prediction)\n",
    "\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin_svm = SVC(kernel=\"linear\", C=0.025, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lin_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_pred = lin_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective_svm(space):\n",
    "    \n",
    "#     model = SVC(C=space['C'],\n",
    "#                 gamma=space['gamma'],\n",
    "#                 degree=space['degree'],\n",
    "#                 kernel='linear',\n",
    "#                 probability=True\n",
    "#                )\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     pred = model.predict(X_test)\n",
    "#     score = cohen_kappa_score(y_test, pred)\n",
    "    \n",
    "#     loss = 1 - score\n",
    "    \n",
    "#     return {'loss': loss, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space={'C': hp.loguniform('C', 0, 1),\n",
    "#        'gamma' : hp.loguniform('gamma', 0, 1),\n",
    "#        'degree': scope.int(hp.choice('degree', [1, 2, 3, 5]))\n",
    "#       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params_svm = fmin(\n",
    "#     fn=objective_svm,\n",
    "#     space=space,\n",
    "#     algo=tpe.suggest,\n",
    "#     trials=svm_trials,\n",
    "#     max_evals=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model = getBestModelfromTrials(svm_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
